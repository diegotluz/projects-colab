{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Exercício 1 - Aula 2**"
      ],
      "metadata": {
        "id": "b_lUc0-cLsVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dado o dataset de produtos [1], desenvolva os seguintes pipelines:\n",
        "\n",
        "[1] - https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\n",
        "\n",
        "Obs.: em todos os pipelines use:\n",
        "- normalização renovendo valores faltantes\n",
        "- criem uma nova coluna concatenando as colunas nome e descrição.\n",
        "- randon_state igual a 42 para permitir a comparação com seus colegas e separe uma amostra de 30% para teste.\n"
      ],
      "metadata": {
        "id": "aFDcwRhD-Wrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pacotes utilizados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# carregar dataframe\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "\n",
        "# limpeza inicial (normalização)\n",
        "df.dropna(inplace=True)\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao']\n",
        "\n",
        "# divisão da amostra entre treino e teste\n",
        "df_train, df_test = train_test_split(\n",
        "      df,\n",
        "      test_size = 0.3,\n",
        "      random_state = 42\n",
        "  )"
      ],
      "metadata": {
        "id": "XjpvUZj5IPpG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. ) Treine um modelo de classificação DecisionTreeClassifier do pacote scikit-learn para classificar os produtos em suas categorias, com as seguintes configurações usando a nova coluna (nome + descricao):\n",
        "\n",
        "- 1.1 Contagem de termos simples com unigrama e sem stop-words.\n",
        "- 1.2 Contagem de termos simples com unigrama + brigrama e sem stop-words.\n",
        "- 1.3 TF-IDF com unigrama e com stop-words.\n",
        "- 1.4 TF-IDF com unigrama e sem stop-words.\n",
        "- 1.5 TF-IDF com unigrama e sem stop-words em textos lematizados (Dica: crie uma função para lematizar o texto usando o Spacy)."
      ],
      "metadata": {
        "id": "hEgJjADlSCWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Contagem de termos simples com unigrama e sem stop-words.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stops = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# vetorização\n",
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=stops)\n",
        "vect.fit(df_train.texto)\n",
        "text_vect_train = vect.transform(df_train.texto)\n",
        "\n",
        "x_train = text_vect_train\n",
        "y_train = df_train[\"categoria\"]\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# treinamento do modelo\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# teste do modelo\n",
        "x_test = vect.transform(df_test.texto)\n",
        "y_test = df_test[\"categoria\"]\n",
        "\n",
        "model.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "NgGpOZiISyb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be85fd0-96a8-4cd3-ff07-a7bdd82f19f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9611428571428572"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Contagem de termos simples com unigrama + brigrama e sem stop-words.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stops = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# vetorização\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops)\n",
        "vect.fit(df_train.texto)\n",
        "text_vect_train = vect.transform(df_train.texto)\n",
        "\n",
        "x_train = text_vect_train\n",
        "y_train = df_train[\"categoria\"]\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# treinamento do modelo\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# teste do modelo\n",
        "x_test = vect.transform(df_test.texto)\n",
        "y_test = df_test[\"categoria\"]\n",
        "\n",
        "model.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "vWhdN8OgJk2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2183d6b0-104e-4a14-9128-67144d1b403e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9565714285714285"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 TF-IDF com unigrama e com stop-words.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# vetorização\n",
        "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
        "vect.fit(df_train.texto)\n",
        "text_vect_train = vect.transform(df_train.texto)\n",
        "\n",
        "x_train = text_vect_train\n",
        "y_train = df_train[\"categoria\"]\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# treinamento do modelo\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# teste do modelo\n",
        "x_test = vect.transform(df_test.texto)\n",
        "y_test = df_test[\"categoria\"]\n",
        "\n",
        "model.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "53t9KVF-Jk0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711a6908-0ea6-476c-b38d-eecaa7c28d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9531428571428572"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.4 TF-IDF com unigrama e sem stop-words.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stops = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# vetorização\n",
        "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops)\n",
        "vect.fit(df_train.texto)\n",
        "text_vect_train = vect.transform(df_train.texto)\n",
        "\n",
        "x_train = text_vect_train\n",
        "y_train = df_train[\"categoria\"]\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# treinamento do modelo\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# teste do modelo\n",
        "x_test = vect.transform(df_test.texto)\n",
        "y_test = df_test[\"categoria\"]\n",
        "\n",
        "model.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "BUtJH7PoJkyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74983b29-5d69-4ddd-cb1f-5ff644f940d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9565714285714285"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "ErxxuzB3PYZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.5 TF-IDF com unigrama e sem stop-words em textos lematizados (Dica: crie uma função para lematizar o texto usando o Spacy).\n",
        "# função de lematização completa do documento\n",
        "def lemmatizer_text(text):\n",
        "  sent = []\n",
        "  doc = nlp(text)\n",
        "  for word in doc:\n",
        "      sent.append(word.lemma_)\n",
        "  return \" \".join(sent)\n",
        "\n",
        "# teste das funções de lematização\n",
        "import spacy\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "# validação das funções\n",
        "print(lemmatizer_text('correndo 1, 2, 3'))"
      ],
      "metadata": {
        "id": "_u-CeePTJkv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66142f6-b04b-4d00-a611-85d8fa4a7839"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correr 1 , 2 , 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.5 TF-IDF com unigrama e sem stop-words em textos lematizados (Dica: crie uma função para lematizar o texto usando o Spacy).\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import spacy\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "stops = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# função de lematização completa do documento\n",
        "def lemmatizer_text(text):\n",
        "  sent = []\n",
        "  doc = nlp(text)\n",
        "  for word in doc:\n",
        "      sent.append(word.lemma_)\n",
        "  return \" \".join(sent)\n",
        "\n",
        "# aplica a lematização no dataframe de treino criando um nova coluna\n",
        "df_train['text_lemma'] = df_train.texto.apply(lemmatizer_text)\n",
        "\n",
        "# vetorização\n",
        "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops)\n",
        "vect.fit(df_train.text_lemma)\n",
        "text_vect_train = vect.transform(df_train.text_lemma)\n",
        "\n",
        "x_train = text_vect_train\n",
        "y_train = df_train[\"categoria\"]\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# treinamento do modelo\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# teste do modelo\n",
        "# aplica a lematização no dataframe de treino criando um nova coluna\n",
        "df_test['text_lemma'] = df_test.texto.apply(lemmatizer_text)\n",
        "x_test = vect.transform(df_test.text_lemma)\n",
        "y_test = df_test[\"categoria\"]\n",
        "\n",
        "model.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "_I5FEB5XPHg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf59064e-65f1-4034-fc33-de6e63bafbf6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9394285714285714"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}